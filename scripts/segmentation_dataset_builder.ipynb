{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5fdfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "def prepare_yolo_segmentation_dataset(input_dir, output_dir, val_split=0.1, test_split=0.1):\n",
    "\n",
    "    image_dir = Path(input_dir) / \"image\"\n",
    "    mask_dir = Path(input_dir) / \"mask_seg\"\n",
    "    \n",
    "    assert image_dir.exists() and mask_dir.exists(), \"–ü–∞–ø–∫–∏ 'image' –∏ 'mask_seg' –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!\"\n",
    "\n",
    "    pairs = []\n",
    "    for img_file in os.listdir(image_dir):\n",
    "        if img_file.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            mask_file = f\"{base_name}.txt\"\n",
    "            if os.path.exists(mask_dir / mask_file):\n",
    "                pairs.append((image_dir / img_file, mask_dir / mask_file))\n",
    "    \n",
    "    print(f\"–ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä: {len(pairs)}\")\n",
    "\n",
    "    random.shuffle(pairs)\n",
    "\n",
    "    n_total = len(pairs)\n",
    "    n_val = int(n_total * val_split)\n",
    "    n_test = int(n_total * test_split)\n",
    "    n_train = n_total - n_val - n_test\n",
    "\n",
    "    splits = {\n",
    "        \"train\": pairs[:n_train],\n",
    "        \"val\": pairs[n_train:n_train + n_val],\n",
    "        \"test\": pairs[n_train + n_val:]\n",
    "    }\n",
    "\n",
    "    for split in splits:\n",
    "        for sub in [\"images\", \"labels\"]:\n",
    "            Path(output_dir, split, sub).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for split, items in splits.items():\n",
    "        for img_path, txt_path in tqdm(items, desc=f\"üì¶ –ö–æ–ø–∏—Ä—É–µ–º {split}\"):\n",
    "            shutil.copy(img_path, Path(output_dir, split, \"images\", img_path.name))\n",
    "            shutil.copy(txt_path, Path(output_dir, split, \"labels\", txt_path.name))\n",
    "\n",
    "    data_yaml = {\n",
    "        \"train\": str(Path(output_dir) / \"train\" / \"images\").replace(\"\\\\\", \"/\"),\n",
    "        \"val\": str(Path(output_dir) / \"val\" / \"images\").replace(\"\\\\\", \"/\"),\n",
    "        \"test\": str(Path(output_dir) / \"test\" / \"images\").replace(\"\\\\\", \"/\"),\n",
    "        \"nc\": 3,\n",
    "        \"names\": [\"base\", \"solar_panel\", \"payload\"]\n",
    "    }\n",
    "\n",
    "    with open(Path(output_dir) / \"data.yaml\", \"w\") as f:\n",
    "        yaml.dump(data_yaml, f)\n",
    "\n",
    "    print(f\"\\n–î–∞—Ç–∞—Å–µ—Ç –≥–æ—Ç–æ–≤. YAML —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {Path(output_dir) / 'data.yaml'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d2871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ –ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä: 1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "üì¶ –ö–æ–ø–∏—Ä—É–µ–º train: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1120/1120 [00:24<00:00, 46.13it/s]\n",
      "üì¶ –ö–æ–ø–∏—Ä—É–µ–º val: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 140/140 [00:02<00:00, 51.16it/s]\n",
      "üì¶ –ö–æ–ø–∏—Ä—É–µ–º test: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 140/140 [00:02<00:00, 51.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ –î–∞—Ç–∞—Å–µ—Ç –≥–æ—Ç–æ–≤. YAML —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: D:\\Paper_1\\segmentation\\datasets\\icesat2\\data.yaml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_dir = r\"D:\\Paper_1\\renders\\icesat2\"\n",
    "output_dir = r\"D:\\Paper_1\\segmentation\\datasets\\icesat2\"\n",
    "\n",
    "prepare_yolo_segmentation_dataset(input_dir, output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
